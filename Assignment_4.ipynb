{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNxyYRW8bskKAwyRIqLGLVC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karan1106/Assignment3/blob/master/Assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXybjfeBDF2t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "406c3750-82a0-440f-b9dc-6e26475fec7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaFT9pn6FWJU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8f3707d7-158a-4468-e309-d433504ca171"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCsvqEwbFX_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import random\n",
        "from scipy import ndarray"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJVs7XprKH08",
        "colab_type": "text"
      },
      "source": [
        "BUILDING CONVOLUTIONAL NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBINA1l8KDZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8a49dc8-7aeb-4798-9072-c4bc0911924e"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from keras import backend as K"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoMhnpsKMIe-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "07e02b97-6c82-41f4-93e5-2f4acdccbc0d"
      },
      "source": [
        "# dimensions of our images.\n",
        "#input_shape=(256,256,3)\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "\n",
        "trdata = ImageDataGenerator()\n",
        "traindata = trdata.flow_from_directory(directory=\"/content/gdrive/My Drive/Colab Notebooks/A4 Augmented images\")\n",
        "tsdata = ImageDataGenerator()\n",
        "testdata = tsdata.flow_from_directory(directory=\"/content/gdrive/My Drive/Colab Notebooks/Scrap_test\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1842 images belonging to 3 classes.\n",
            "Found 308 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwWfVS9TMSuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "nb_train_samples=1842\n",
        "nb_validation_samples=308\n",
        "batch_size=32\n",
        "epochs=20"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHStfs96NwpT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e432ef1a-0e20-4aff-d7f1-6c25ae2a7b04"
      },
      "source": [
        "#model building\n",
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(256,256,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "#flatten layer\n",
        "model.add(Flatten()) # Output convert into one dimension layer and will go to Dense layer\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1gSvA4TODmO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6c799ed-5227-4737-8d91-fd60c61bdcc9"
      },
      "source": [
        "model.summary()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 128)       512       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 256)       1024      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 16, 16, 512)       2048      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                2097216   \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 6         \n",
            "=================================================================\n",
            "Total params: 16,817,863\n",
            "Trainable params: 16,814,919\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIL2UY32jbgy",
        "colab_type": "text"
      },
      "source": [
        "SGD OPTIMIZER\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDtVe-RfOE3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "checkpoint= ModelCheckpoint(\"Modelsgd.h5\", monitor=\"val_accuracy\",mode='max', save_best_only=True,verbose=1)\n",
        "\n",
        "earlystop= EarlyStopping(monitor=\"val_accuracy\",min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
        "\n",
        "reduce_lr= ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.2, patience=5, verbose=1, min_delta=0.001)\n",
        "\n",
        "#putiing callbacks into callback list\n",
        "callbacks = [earlystop, checkpoint, reduce_lr]\n",
        "momentums = [0.0, 0.5, 0.9, 0.99]\n",
        "opt = SGD(lr=0.01, momentum=0.5, decay=0.01)\n",
        "#we use a very small learning rate\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHOko6gdVyw4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2ae34ed3-40b5-4df2-9161-138a56d0c170"
      },
      "source": [
        "history=model.fit_generator(\n",
        "    traindata,\n",
        "    steps_per_epoch=nb_train_samples//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=testdata,\n",
        "    validation_steps=nb_validation_samples//batch_size,\n",
        "    callbacks = [earlystop, checkpoint, reduce_lr])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/20\n",
            "57/57 [==============================] - 408s 7s/step - loss: 0.9017 - accuracy: 0.5431 - val_loss: 0.9035 - val_accuracy: 0.4861\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.48611, saving model to Modelsgd.h5\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 76s 1s/step - loss: 0.5374 - accuracy: 0.6630 - val_loss: 0.9362 - val_accuracy: 0.5543\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.48611 to 0.55435, saving model to Modelsgd.h5\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.5012 - accuracy: 0.6765 - val_loss: 0.5118 - val_accuracy: 0.6304\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.55435 to 0.63043, saving model to Modelsgd.h5\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4816 - accuracy: 0.6876 - val_loss: 0.4280 - val_accuracy: 0.6884\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.63043 to 0.68841, saving model to Modelsgd.h5\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4705 - accuracy: 0.6845 - val_loss: 0.4676 - val_accuracy: 0.6812\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.68841\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4550 - accuracy: 0.6873 - val_loss: 0.4944 - val_accuracy: 0.7174\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.68841 to 0.71739, saving model to Modelsgd.h5\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4561 - accuracy: 0.6989 - val_loss: 0.5160 - val_accuracy: 0.6848\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.71739\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4368 - accuracy: 0.7144 - val_loss: 0.4639 - val_accuracy: 0.6848\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.71739\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4386 - accuracy: 0.7204 - val_loss: 0.3820 - val_accuracy: 0.7862\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.71739 to 0.78623, saving model to Modelsgd.h5\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4236 - accuracy: 0.7387 - val_loss: 0.4032 - val_accuracy: 0.6957\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.78623\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4234 - accuracy: 0.7315 - val_loss: 0.4965 - val_accuracy: 0.8785\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.78623 to 0.87847, saving model to Modelsgd.h5\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4157 - accuracy: 0.7464 - val_loss: 0.2922 - val_accuracy: 0.8370\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.87847\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.4079 - accuracy: 0.7619 - val_loss: 0.4359 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.87847\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.3989 - accuracy: 0.7801 - val_loss: 0.3544 - val_accuracy: 0.7246\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.87847\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.3877 - accuracy: 0.7923 - val_loss: 0.3915 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.87847\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.3893 - accuracy: 0.7823 - val_loss: 0.3233 - val_accuracy: 0.8370\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.87847\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 00016: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3ObU7kpW7ud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1icBjVVek4cW",
        "colab_type": "text"
      },
      "source": [
        "ADAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtTtSsMHk6o5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint= ModelCheckpoint(\"Modeladam.h5\", monitor=\"val_accuracy\",mode='max', save_best_only=True,verbose=1)\n",
        "\n",
        "earlystop= EarlyStopping(monitor=\"val_accuracy\",min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
        "\n",
        "reduce_lr= ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.2, patience=5, verbose=1, min_delta=0.001)\n",
        "\n",
        "#putiing callbacks into callback list\n",
        "callbacks = [earlystop, checkpoint, reduce_lr]\n",
        "opt = Adam(lr=0.01, decay=0.01)\n",
        "#we use a very small learning rate\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cudfVd2elEHq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "outputId": "50a44bd0-83d6-406c-ff1a-c2334ff51953"
      },
      "source": [
        "history=model.fit_generator(\n",
        "    traindata,\n",
        "    steps_per_epoch=nb_train_samples//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=testdata,\n",
        "    validation_steps=nb_validation_samples//batch_size,\n",
        "    callbacks = [earlystop, checkpoint, reduce_lr])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 69s 1s/step - loss: 4.4517 - accuracy: 0.3746 - val_loss: 75.9680 - val_accuracy: 0.3507\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.35069, saving model to Modeladam.h5\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 1.0073 - accuracy: 0.3746 - val_loss: 4.7033 - val_accuracy: 0.4058\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.35069 to 0.40580, saving model to Modeladam.h5\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.9694 - accuracy: 0.4354 - val_loss: 0.8944 - val_accuracy: 0.4819\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.40580 to 0.48188, saving model to Modeladam.h5\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.9188 - accuracy: 0.4564 - val_loss: 0.6570 - val_accuracy: 0.5725\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.48188 to 0.57246, saving model to Modeladam.h5\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.8954 - accuracy: 0.4768 - val_loss: 0.9496 - val_accuracy: 0.5109\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.57246\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.8362 - accuracy: 0.4836 - val_loss: 0.9849 - val_accuracy: 0.5507\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.57246\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.7597 - accuracy: 0.5580 - val_loss: 0.5713 - val_accuracy: 0.7138\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.57246 to 0.71377, saving model to Modeladam.h5\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.6928 - accuracy: 0.5802 - val_loss: 0.7480 - val_accuracy: 0.5616\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.71377\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.7070 - accuracy: 0.5800 - val_loss: 0.5091 - val_accuracy: 0.6522\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.71377\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.6810 - accuracy: 0.6013 - val_loss: 0.5799 - val_accuracy: 0.6920\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.71377\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.6596 - accuracy: 0.5972 - val_loss: 0.8521 - val_accuracy: 0.4757\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.71377\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.6500 - accuracy: 0.6099 - val_loss: 0.5424 - val_accuracy: 0.6232\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.71377\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVR3o0RPl_dO",
        "colab_type": "text"
      },
      "source": [
        "NADAM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iL1YRfOmAwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from keras.optimizers import Nadam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint= ModelCheckpoint(\"Modelnadam.h5\", monitor=\"val_accuracy\",mode='max', save_best_only=True,verbose=1)\n",
        "\n",
        "earlystop= EarlyStopping(monitor=\"val_accuracy\",min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
        "\n",
        "reduce_lr= ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.2, patience=5, verbose=1, min_delta=0.001)\n",
        "\n",
        "#putiing callbacks into callback list\n",
        "callbacks = [earlystop, checkpoint, reduce_lr]\n",
        "opt = Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
        "#we use a very small learning rate\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_4mtriElNR8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51d6961f-f468-4160-b153-092ef4809707"
      },
      "source": [
        "history=model.fit_generator(\n",
        "    traindata,\n",
        "    steps_per_epoch=nb_train_samples//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=testdata,\n",
        "    validation_steps=nb_validation_samples//batch_size,\n",
        "    callbacks = [earlystop, checkpoint, reduce_lr])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 69s 1s/step - loss: 0.7121 - accuracy: 0.5785 - val_loss: 1.0655 - val_accuracy: 0.4549\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.45486, saving model to Modelnadam.h5\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.6654 - accuracy: 0.5884 - val_loss: 1.1781 - val_accuracy: 0.3804\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.45486\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.6214 - accuracy: 0.6144 - val_loss: 0.5089 - val_accuracy: 0.6703\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.45486 to 0.67029, saving model to Modelnadam.h5\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.5724 - accuracy: 0.6122 - val_loss: 0.6200 - val_accuracy: 0.6594\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.67029\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.5283 - accuracy: 0.6575 - val_loss: 0.4800 - val_accuracy: 0.6341\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.67029\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.5390 - accuracy: 0.6497 - val_loss: 0.6172 - val_accuracy: 0.5326\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.67029\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.5133 - accuracy: 0.6641 - val_loss: 0.4285 - val_accuracy: 0.6630\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.67029\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.4971 - accuracy: 0.6646 - val_loss: 0.4969 - val_accuracy: 0.6739\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.67029 to 0.67391, saving model to Modelnadam.h5\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.5022 - accuracy: 0.6602 - val_loss: 0.6402 - val_accuracy: 0.5833\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.67391\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.5018 - accuracy: 0.6829 - val_loss: 0.4019 - val_accuracy: 0.7464\n",
            "\n",
            "Epoch 00010: val_accuracy improved from 0.67391 to 0.74638, saving model to Modelnadam.h5\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.5175 - accuracy: 0.6729 - val_loss: 0.7227 - val_accuracy: 0.6944\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.74638\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.4706 - accuracy: 0.7072 - val_loss: 0.5446 - val_accuracy: 0.6703\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.74638\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.4763 - accuracy: 0.7260 - val_loss: 0.5256 - val_accuracy: 0.7790\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.74638 to 0.77899, saving model to Modelnadam.h5\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.4858 - accuracy: 0.7519 - val_loss: 1.1356 - val_accuracy: 0.6087\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.77899\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.4842 - accuracy: 0.7641 - val_loss: 0.4446 - val_accuracy: 0.8080\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.77899 to 0.80797, saving model to Modelnadam.h5\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.4268 - accuracy: 0.8033 - val_loss: 0.4995 - val_accuracy: 0.8043\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.80797\n",
            "Epoch 17/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.4099 - accuracy: 0.8133 - val_loss: 2.5201 - val_accuracy: 0.3478\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.80797\n",
            "Epoch 18/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.4041 - accuracy: 0.8448 - val_loss: 19.1203 - val_accuracy: 0.4855\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.80797\n",
            "Epoch 19/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.3733 - accuracy: 0.8624 - val_loss: 1.2419 - val_accuracy: 0.6051\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.80797\n",
            "Epoch 20/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.3330 - accuracy: 0.8829 - val_loss: 0.3029 - val_accuracy: 0.9312\n",
            "\n",
            "Epoch 00020: val_accuracy improved from 0.80797 to 0.93116, saving model to Modelnadam.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm1tB3eZmbQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHq2S4g2qo-K",
        "colab_type": "text"
      },
      "source": [
        "RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRYMGYSEqiwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "checkpoint= ModelCheckpoint(\"Modelrmsprop.h5\", monitor=\"val_accuracy\",mode='max', save_best_only=True,verbose=1)\n",
        "\n",
        "earlystop= EarlyStopping(monitor=\"val_accuracy\",min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
        "\n",
        "reduce_lr= ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.2, patience=5, verbose=1, min_delta=0.001)\n",
        "\n",
        "#putiing callbacks into callback list\n",
        "callbacks = [earlystop, checkpoint, reduce_lr]\n",
        "momentums = [0.0, 0.5, 0.9, 0.99]\n",
        "opt = RMSprop(lr=0.01)\n",
        "#we use a very small learning rate\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M66zohBArbbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "762aaebd-985c-4379-f916-3ed2502c1b87"
      },
      "source": [
        "history=model.fit_generator(\n",
        "    traindata,\n",
        "    steps_per_epoch=nb_train_samples//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=testdata,\n",
        "    validation_steps=nb_validation_samples//batch_size,\n",
        "    callbacks = [earlystop, checkpoint, reduce_lr])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 68s 1s/step - loss: 1.7592 - accuracy: 0.3580 - val_loss: 1.1373 - val_accuracy: 0.3507\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.35069, saving model to Modelrmsprop.h5\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.9797 - accuracy: 0.4829 - val_loss: 0.4205 - val_accuracy: 0.6739\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.35069 to 0.67391, saving model to Modelrmsprop.h5\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 66s 1s/step - loss: 0.7425 - accuracy: 0.6195 - val_loss: 1.1811 - val_accuracy: 0.6594\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.67391\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.6589 - accuracy: 0.6565 - val_loss: 4.7983 - val_accuracy: 0.4565\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.67391\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.6269 - accuracy: 0.6442 - val_loss: 0.4429 - val_accuracy: 0.6703\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.67391\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.6019 - accuracy: 0.6785 - val_loss: 503.8398 - val_accuracy: 0.3188\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.67391\n",
            "Epoch 7/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.5477 - accuracy: 0.7127 - val_loss: 1.6806 - val_accuracy: 0.3913\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.67391\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 00007: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy9rGz78sQ84",
        "colab_type": "text"
      },
      "source": [
        " Nesterov Accelerated Gradient Descent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e76eoofrhrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import Callback\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "checkpoint= ModelCheckpoint(\"ModelNag.h5\", monitor=\"val_accuracy\",mode='max', save_best_only=True,verbose=1)\n",
        "\n",
        "earlystop= EarlyStopping(monitor=\"val_accuracy\",min_delta=0,patience=5,verbose=1,restore_best_weights=True)\n",
        "\n",
        "reduce_lr= ReduceLROnPlateau(monitor=\"val_accuracy\", factor=0.2, patience=5, verbose=1, min_delta=0.001)\n",
        "\n",
        "#putiing callbacks into callback list\n",
        "callbacks = [earlystop, checkpoint, reduce_lr]\n",
        "opt = SGD(lr=0.01, nesterov=True)\n",
        "#we use a very small learning rate\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgYj_oqVsYcr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "91f00ce9-745d-4160-84f0-7a16dae3b41b"
      },
      "source": [
        "history=model.fit_generator(\n",
        "    traindata,\n",
        "    steps_per_epoch=nb_train_samples//batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=testdata,\n",
        "    validation_steps=nb_validation_samples//batch_size,\n",
        "    callbacks = [earlystop, checkpoint, reduce_lr])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "57/57 [==============================] - 67s 1s/step - loss: 0.7542 - accuracy: 0.5967 - val_loss: 2.2153 - val_accuracy: 0.3299\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.32986, saving model to ModelNag.h5\n",
            "Epoch 2/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7287 - accuracy: 0.6210 - val_loss: 2.6945 - val_accuracy: 0.3333\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.32986 to 0.33333, saving model to ModelNag.h5\n",
            "Epoch 3/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7250 - accuracy: 0.6061 - val_loss: 1.5040 - val_accuracy: 0.3370\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.33333 to 0.33696, saving model to ModelNag.h5\n",
            "Epoch 4/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7402 - accuracy: 0.6127 - val_loss: 1.6601 - val_accuracy: 0.3188\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.33696\n",
            "Epoch 5/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7015 - accuracy: 0.6116 - val_loss: 2.0346 - val_accuracy: 0.3225\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.33696\n",
            "Epoch 6/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7237 - accuracy: 0.6122 - val_loss: 1.1960 - val_accuracy: 0.3659\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.33696 to 0.36594, saving model to ModelNag.h5\n",
            "Epoch 7/20\n",
            "56/57 [============================>.] - ETA: 1s - loss: 0.7226 - accuracy: 0.6010\n",
            "Epoch 00007: val_accuracy did not improve from 0.36594\n",
            "Epoch 8/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7461 - accuracy: 0.6069 - val_loss: 0.6239 - val_accuracy: 0.6014\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.36594 to 0.60145, saving model to ModelNag.h5\n",
            "Epoch 9/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7171 - accuracy: 0.6110 - val_loss: 0.4973 - val_accuracy: 0.7065\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.60145 to 0.70652, saving model to ModelNag.h5\n",
            "Epoch 10/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7171 - accuracy: 0.6234 - val_loss: 0.6739 - val_accuracy: 0.6087\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.70652\n",
            "Epoch 11/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7151 - accuracy: 0.6114 - val_loss: 0.5830 - val_accuracy: 0.7118\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.70652 to 0.71181, saving model to ModelNag.h5\n",
            "Epoch 12/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7089 - accuracy: 0.6122 - val_loss: 0.5262 - val_accuracy: 0.6812\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.71181\n",
            "Epoch 13/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7090 - accuracy: 0.6212 - val_loss: 0.6229 - val_accuracy: 0.6159\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.71181\n",
            "Epoch 14/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.6952 - accuracy: 0.6281 - val_loss: 0.5497 - val_accuracy: 0.6993\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.71181\n",
            "Epoch 15/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7150 - accuracy: 0.5932 - val_loss: 0.6856 - val_accuracy: 0.6341\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.71181\n",
            "Epoch 16/20\n",
            "57/57 [==============================] - 65s 1s/step - loss: 0.7054 - accuracy: 0.6075 - val_loss: 0.5691 - val_accuracy: 0.6522\n",
            "Restoring model weights from the end of the best epoch\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.71181\n",
            "\n",
            "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
            "Epoch 00016: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zd2NapnsfJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}